{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "s1hlq32y8j",
   "metadata": {},
   "source": [
    "# 02. LangChain 캐싱(Caching) 가이드\n",
    "\n",
    "이 노트북에서는 LangChain의 캐싱 기능을 사용하여 LLM 호출 비용을 절감하고 성능을 향상시키는 방법을 배웁니다.\n",
    "\n",
    "## 목차\n",
    "1. LangSmith 설정 및 연결\n",
    "2. InMemory Cache\n",
    "3. SQLite Cache\n",
    "4. 성능 비교 및 모범 사례\n",
    "\n",
    "## 개요\n",
    "\n",
    "캐싱은 동일한 입력에 대한 LLM의 응답을 저장하여 재사용하는 기법입니다. 이를 통해:\n",
    "- **비용 절감**: 동일한 쿼리에 대해 API 호출을 반복하지 않음\n",
    "- **응답 속도 향상**: 캐시된 결과는 즉시 반환됨\n",
    "- **일관성 보장**: 동일한 입력에 대해 항상 같은 응답을 받음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y7bu7gynf8n",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 LangSmith 연결\n",
    "\n",
    "먼저 필요한 패키지를 임포트하고 환경 변수를 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eff0aa",
   "metadata": {},
   "source": [
    "## 0. 필수 패키지 설치\n",
    "\n",
    "이 노트북을 실행하기 전에 필요한 패키지들을 설치해야 합니다.\n",
    "\n",
    "### 필요한 패키지\n",
    "- `langchain_community`: 캐싱 기능 제공\n",
    "- `langsmith`: LangSmith 추적 및 모니터링\n",
    "- `langchain_google_genai`: Google Gemini 모델 사용\n",
    "- `python-dotenv`: 환경 변수 관리\n",
    "\n",
    "### 설치 명령어\n",
    "```bash\n",
    "# uv를 사용하는 경우\n",
    "uv add langchain_community langsmith langchain_google_genai python-dotenv\n",
    "\n",
    "# pip를 사용하는 경우\n",
    "pip install langchain_community langsmith langchain_google_genai python-dotenv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anbpbnrnso",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_community.cache import InMemoryCache, SQLiteCache\n",
    "import time\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 확인\n",
    "print(\"🔍 환경 변수 확인 중...\")\n",
    "\n",
    "# Google API 키 확인\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not google_api_key:\n",
    "    raise ValueError(\"❌ GOOGLE_API_KEY가 설정되지 않았습니다. .env 파일을 확인하세요.\")\n",
    "print(\"✅ Google API Key: 설정됨\")\n",
    "\n",
    "# LangSmith API 키 확인 (선택사항)\n",
    "langsmith_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "if langsmith_api_key:\n",
    "    print(\"✅ LangSmith API Key: 설정됨\")\n",
    "    # LangSmith 설정\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # LangSmith 추적 활성화\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"cache-demo\"  # 프로젝트 이름 설정\n",
    "    \n",
    "    print(f\"📊 LangSmith 프로젝트: {os.environ['LANGCHAIN_PROJECT']}\")\n",
    "    print(f\"🔄 LangSmith 추적 활성화: {os.environ['LANGCHAIN_TRACING_V2']}\")\n",
    "    print(\"🌐 LangSmith 대시보드: https://smith.langchain.com/\")\n",
    "else:\n",
    "    print(\"⚠️  LangSmith API Key가 설정되지 않았습니다.\")\n",
    "    print(\"   LangSmith 추적 없이 계속 진행합니다.\")\n",
    "    print(\"   추적을 원한다면 .env 파일에 LANGCHAIN_API_KEY를 추가하세요.\")\n",
    "\n",
    "print(\"\\n✅ 환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0447706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 패키지 설치 상태 확인\n",
    "try:\n",
    "    import langchain_community\n",
    "    print(\"✅ langchain_community 설치됨\")\n",
    "    print(f\"   버전: {langchain_community.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ langchain_community 패키지 설치 필요\")\n",
    "    print(f\"   에러: {e}\")\n",
    "    print(\"   해결: uv add langchain_community\")\n",
    "\n",
    "try:\n",
    "    import langsmith\n",
    "    print(\"✅ langsmith 설치됨\")\n",
    "    print(f\"   버전: {langsmith.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ langsmith 패키지 설치 필요\")\n",
    "    print(f\"   에러: {e}\")\n",
    "    print(\"   해결: uv add langsmith\")\n",
    "\n",
    "try:\n",
    "    from langchain_community.cache import InMemoryCache, SQLiteCache\n",
    "    print(\"✅ 캐시 클래스 임포트 성공\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ 캐시 클래스 임포트 실패\")\n",
    "    print(f\"   에러: {e}\")\n",
    "\n",
    "try:\n",
    "    from langchain.globals import set_llm_cache\n",
    "    print(\"✅ LLM 캐시 설정 함수 임포트 성공\")\n",
    "except ImportError as e:\n",
    "    print(\"❌ LLM 캐시 설정 함수 임포트 실패\")\n",
    "    print(f\"   에러: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dltlbuk5lsn",
   "metadata": {},
   "source": [
    "### 🔗 LangSmith 프로젝트 연결 가이드\n",
    "\n",
    "LangSmith는 LangChain 애플리케이션의 디버깅, 테스팅, 모니터링을 위한 플랫폼입니다.\n",
    "\n",
    "#### 📋 단계별 설정 방법\n",
    "\n",
    "**1단계: LangSmith 계정 생성**\n",
    "- [LangSmith 웹사이트](https://smith.langchain.com/)에 접속\n",
    "- 계정 생성 또는 로그인\n",
    "- 새 프로젝트 생성\n",
    "\n",
    "**2단계: API 키 발급**\n",
    "- LangSmith 대시보드에서 Settings → API Keys 메뉴\n",
    "- \"Create API Key\" 클릭\n",
    "- API 키 복사 (한 번만 표시됨!)\n",
    "\n",
    "**3단계: .env 파일 설정**\n",
    "```env\n",
    "# .env 파일에 추가\n",
    "GOOGLE_API_KEY=your_google_api_key\n",
    "LANGCHAIN_API_KEY=your_langsmith_api_key\n",
    "```\n",
    "\n",
    "**4단계: 환경 변수 설정 (아래 코드셀에서 자동 처리)**\n",
    "- `LANGCHAIN_TRACING_V2=\"true\"`: 추적 활성화\n",
    "- `LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"`: API 엔드포인트\n",
    "- `LANGCHAIN_PROJECT=\"your-project-name\"`: 프로젝트 이름\n",
    "\n",
    "#### 🎯 LangSmith의 주요 기능\n",
    "\n",
    "1. **실시간 추적**: 모든 LLM 호출 모니터링\n",
    "2. **성능 분석**: 응답 시간, 토큰 사용량, 비용 추적\n",
    "3. **디버깅**: 프롬프트와 응답 체인 시각화\n",
    "4. **A/B 테스팅**: 다른 모델/프롬프트 성능 비교\n",
    "5. **데이터셋 관리**: 테스트 케이스 저장 및 평가\n",
    "\n",
    "#### ⚠️ 주의사항\n",
    "- API 키는 절대 코드에 직접 입력하지 마세요\n",
    "- .env 파일을 .gitignore에 추가하세요\n",
    "- 무료 플랜은 월 5,000개 트레이스 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fgq33ppj05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,  # 일관된 응답을 위해 0으로 설정\n",
    "    max_output_tokens=100\n",
    ")\n",
    "\n",
    "# 테스트 메시지\n",
    "test_message = \"파이썬의 주요 특징 3가지를 간단히 설명해주세요.\"\n",
    "\n",
    "print(\"LLM 모델 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f346k01u",
   "metadata": {},
   "source": [
    "## 2. InMemory Cache\n",
    "\n",
    "InMemory Cache는 응답을 메모리에 저장하는 가장 간단한 캐싱 방법입니다.\n",
    "\n",
    "### 특징\n",
    "- **빠른 속도**: 메모리에서 직접 읽기/쓰기\n",
    "- **휘발성**: 프로그램 종료 시 캐시 데이터 손실\n",
    "- **용도**: 개발/테스트 환경, 단기 실행 애플리케이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rwldiroi3m",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# InMemory Cache\n",
    "############################################################################\n",
    "# ⭐⭐⭐ InMemory Cache 설정\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "print(\"InMemory Cache를 사용한 LLM 호출 테스트\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 첫 번째 호출 (캐시 미스)\n",
    "start_time = time.time()\n",
    "response1 = llm.invoke(test_message)\n",
    "first_call_time = time.time() - start_time\n",
    "\n",
    "print(f\"첫 번째 호출 (캐시 미스):\")\n",
    "print(f\"응답 시간: {first_call_time:.2f}초\")\n",
    "print(f\"응답: {response1.content[:100]}...\")\n",
    "print()\n",
    "\n",
    "# 두 번째 호출 (캐시 히트)\n",
    "start_time = time.time()\n",
    "response2 = llm.invoke(test_message)\n",
    "second_call_time = time.time() - start_time\n",
    "\n",
    "print(f\"두 번째 호출 (캐시 히트):\")\n",
    "print(f\"응답 시간: {second_call_time:.2f}초\")\n",
    "print(f\"응답: {response2.content[:100]}...\")\n",
    "print()\n",
    "\n",
    "print(f\"속도 향상: {first_call_time/second_call_time:.0f}배 빠름\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q51gb0apr1p",
   "metadata": {},
   "source": [
    "### InMemory Cache 고급 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5o58jx2ixza",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 다양한 쿼리로 캐시 테스트\n",
    "############################################################################\n",
    "queries = [\n",
    "    \"파이썬의 주요 특징 3가지를 간단히 설명해주세요.\",  # 이미 캐시됨\n",
    "    \"자바스크립트의 주요 특징을 설명해주세요.\",\n",
    "    \"파이썬의 주요 특징 3가지를 간단히 설명해주시기를 바랍니다.\",  # 캐시에서 못 가져옴\n",
    "    \"머신러닝이란 무엇인가요?\",\n",
    "    \"자바스크립트의 주요 특징을 설명해주시죠.\"  # 캐시에서 못 가져옴\n",
    "]\n",
    "\n",
    "# 질문이 조금이라도 다르면 캐시를 활용하지 못함.\n",
    "# 예: \"설명해주세요\" vs \"설명해주시기를 바랍니다\"\n",
    "# 캐시를 제대로 활용하기 위해서는 질문 문장을 일반화하는 로직 필요\n",
    "\n",
    "print(\"다중 쿼리 캐시 테스트\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(query)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # 캐시 상태 판단\n",
    "    cache_status = \"캐시 히트\" if elapsed_time < 0.1 else \"캐시 미스\"\n",
    "    \n",
    "    print(f\"\\n쿼리 {i}: {query[:30]}...\")\n",
    "    print(f\"상태: {cache_status}\")\n",
    "    print(f\"응답 시간: {elapsed_time:.3f}초\")\n",
    "    print(f\"응답 미리보기: {response.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1vbfq3sze",
   "metadata": {},
   "source": [
    "## 3. SQLite Cache\n",
    "\n",
    "SQLite Cache는 응답을 SQLite 데이터베이스에 저장하여 영구 보존합니다.\n",
    "\n",
    "### 특징\n",
    "- **영구 저장**: 프로그램 종료 후에도 캐시 유지\n",
    "- **파일 기반**: `.db` 파일로 관리\n",
    "- **용도**: 프로덕션 환경, 장기 실행 애플리케이션, 캐시 공유 필요 시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dnzvjvpia4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# SQLite Cache 설정\n",
    "############################################################################\n",
    "sqlite_cache_path = \"langchain_cache.db\"\n",
    "set_llm_cache(SQLiteCache(database_path=sqlite_cache_path))\n",
    "\n",
    "print(\"SQLite Cache를 사용한 LLM 호출 테스트\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 새로운 테스트 쿼리\n",
    "test_queries = [\n",
    "    \"딥러닝과 머신러닝의 차이점은?\",\n",
    "    \"REST API란 무엇인가요?\",\n",
    "    \"딥러닝과 머신러닝의 차이점은?\"  # 동일 쿼리 반복\n",
    "]\n",
    "\n",
    "for idx, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n쿼리 {idx}: {query}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(query)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # 캐시 상태 판단\n",
    "    if elapsed_time < 0.1:\n",
    "        print(\"📦 캐시에서 로드됨!\")\n",
    "    else:\n",
    "        print(\"🔄 새로운 API 호출\")\n",
    "    \n",
    "    print(f\"응답 시간: {elapsed_time:.3f}초\")\n",
    "    print(f\"응답: {response.content[:80]}...\")\n",
    "\n",
    "# DB 파일 정보 출력\n",
    "import os\n",
    "if os.path.exists(sqlite_cache_path):\n",
    "    file_size = os.path.getsize(sqlite_cache_path) / 1024  # KB\n",
    "    print(f\"\\n\\n💾 SQLite 캐시 파일 크기: {file_size:.2f} KB\")\n",
    "\n",
    "# SQLite 캐시 연결 정리\n",
    "print(f\"\\n🧹 SQLite 캐시 연결 정리 중...\")\n",
    "from langchain.globals import get_llm_cache\n",
    "\n",
    "current_cache = get_llm_cache()\n",
    "if current_cache and hasattr(current_cache, 'engine'):\n",
    "    current_cache.engine.dispose()\n",
    "    print(\"✅ SQLite 연결 정리 완료\")\n",
    "\n",
    "# 캐시 무효화 (다음 셀에서 새로운 캐시 설정을 위해)\n",
    "set_llm_cache(None)\n",
    "print(\"✅ 캐시 무효화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "axtavxa4w1b",
   "metadata": {},
   "source": [
    "### SQLite 캐시 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcucd7ndx2r",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# SQLite 캐시 데이터베이스 내용 조회\n",
    "############################################################################\n",
    "import sqlite3\n",
    "\n",
    "# 데이터베이스 연결\n",
    "conn = sqlite3.connect(sqlite_cache_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 테이블 구조 확인\n",
    "print(\"캐시 데이터베이스 구조:\")\n",
    "cursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n",
    "for table in cursor.fetchall():\n",
    "    print(table[0])\n",
    "\n",
    "print(\"\\n\\n캐시된 항목들:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# 캐시 내용 조회 (최근 5개)\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT prompt, response, llm, LENGTH(response) as response_length\n",
    "    FROM full_llm_cache \n",
    "    ORDER BY rowid DESC \n",
    "    LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "for idx, (prompt, response, llm_type, length) in enumerate(cursor.fetchall(), 1):\n",
    "    print(f\"\\n항목 {idx}:\")\n",
    "    print(f\"  프롬프트: {prompt[:50]}...\")\n",
    "    print(f\"  응답 길이: {length} 글자\")\n",
    "    print(f\"  LLM 유형: {llm_type[:50]}...\")\n",
    "    print(f\"  응답 미리보기: {response[:100]}...\")\n",
    "\n",
    "# 전체 캐시 항목 수\n",
    "cursor.execute(\"SELECT COUNT(*) FROM full_llm_cache\")\n",
    "total_items = cursor.fetchone()[0]\n",
    "print(f\"\\n\\n총 캐시된 항목 수: {total_items}개\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# SQLite 캐시 연결 정리 (데이터베이스 조회 후)\n",
    "print(f\"\\n🧹 SQLite 캐시 연결 정리 중...\")\n",
    "from langchain.globals import get_llm_cache\n",
    "\n",
    "current_cache = get_llm_cache()\n",
    "if current_cache and hasattr(current_cache, 'engine'):\n",
    "    current_cache.engine.dispose()\n",
    "    print(\"✅ SQLite 연결 정리 완료\")\n",
    "\n",
    "# 다음 단계를 위해 캐시 무효화\n",
    "set_llm_cache(None)\n",
    "print(\"✅ 캐시 무효화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zkmrrk1z7mp",
   "metadata": {},
   "source": [
    "## 4. 캐시 성능 비교 및 모범 사례"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y9sp6vl40sa",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 캐시 성능 비교\n",
    "############################################################################\n",
    "def benchmark_cache(cache_type, cache_instance, queries, runs=3):\n",
    "    \"\"\"캐시 성능을 측정하는 함수\"\"\"\n",
    "    set_llm_cache(cache_instance)\n",
    "    \n",
    "    results = {\n",
    "        \"cache_type\": cache_type,\n",
    "        \"first_call_times\": [],\n",
    "        \"cached_call_times\": [],\n",
    "        \"total_time\": 0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        for run in range(runs):\n",
    "            for query in queries:\n",
    "                # 첫 호출 (캐시 미스)\n",
    "                start = time.time()\n",
    "                llm.invoke(query)\n",
    "                first_time = time.time() - start\n",
    "                results[\"first_call_times\"].append(first_time)\n",
    "                \n",
    "                # 캐시된 호출 (캐시 히트)\n",
    "                start = time.time()\n",
    "                llm.invoke(query)\n",
    "                cached_time = time.time() - start\n",
    "                results[\"cached_call_times\"].append(cached_time)\n",
    "        \n",
    "        results[\"avg_first_call\"] = sum(results[\"first_call_times\"]) / len(results[\"first_call_times\"])\n",
    "        results[\"avg_cached_call\"] = sum(results[\"cached_call_times\"]) / len(results[\"cached_call_times\"])\n",
    "        results[\"speedup\"] = results[\"avg_first_call\"] / results[\"avg_cached_call\"]\n",
    "        \n",
    "    finally:\n",
    "        # SQLite 캐시인 경우 연결 정리\n",
    "        if hasattr(cache_instance, 'engine') and cache_instance.engine:\n",
    "            cache_instance.engine.dispose()\n",
    "        \n",
    "        # 캐시 무효화 (연결 해제)\n",
    "        set_llm_cache(None)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 테스트 쿼리\n",
    "benchmark_queries = [\n",
    "    \"AI의 미래에 대해 설명해주세요.\",\n",
    "    \"블록체인 기술의 장점은?\",\n",
    "    \"클라우드 컴퓨팅이란?\"\n",
    "]\n",
    "\n",
    "# 벤치마크 실행\n",
    "print(\"캐시 성능 벤치마크\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# InMemory Cache 벤치마크\n",
    "inmemory_results = benchmark_cache(\"InMemory\", InMemoryCache(), benchmark_queries)\n",
    "\n",
    "# SQLite Cache 벤치마크 (새로운 DB 파일 사용)\n",
    "sqlite_results = benchmark_cache(\"SQLite\", SQLiteCache(\"benchmark_cache.db\"), benchmark_queries)\n",
    "\n",
    "# 결과 출력\n",
    "for results in [inmemory_results, sqlite_results]:\n",
    "    print(f\"\\n{results['cache_type']} Cache 성능:\")\n",
    "    print(f\"  평균 첫 호출 시간: {results['avg_first_call']:.3f}초\")\n",
    "    print(f\"  평균 캐시 호출 시간: {results['avg_cached_call']:.3f}초\")\n",
    "    print(f\"  속도 향상: {results['speedup']:.0f}배\")\n",
    "\n",
    "# 정리 (안전한 파일 삭제)\n",
    "import time\n",
    "import gc\n",
    "\n",
    "def safe_remove_file(file_path, max_attempts=5, delay=2):\n",
    "    \"\"\"파일을 안전하게 삭제하는 함수\"\"\"\n",
    "    # 가비지 컬렉션 강제 실행으로 참조 정리\n",
    "    gc.collect()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"✅ {file_path} 삭제 완료\")\n",
    "                return True\n",
    "        except PermissionError:\n",
    "            if attempt < max_attempts - 1:\n",
    "                print(f\"⚠️ {file_path} 삭제 시도 {attempt + 1}/{max_attempts} - 잠시 후 재시도...\")\n",
    "                gc.collect()  # 매 시도마다 가비지 컬렉션\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"❌ {file_path} 삭제 실패: 파일이 사용 중입니다.\")\n",
    "                print(f\"   수동으로 삭제하거나 프로그램 종료 후 삭제하세요.\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {file_path} 삭제 중 오류: {e}\")\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "# 벤치마크용 캐시 파일 정리\n",
    "safe_remove_file(\"benchmark_cache.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fn1kkhrn7ag",
   "metadata": {},
   "source": [
    "### 캐시 사용 모범 사례\n",
    "\n",
    "1. **개발 환경**: InMemory Cache 사용\n",
    "   - 빠른 프로토타이핑\n",
    "   - 테스트 중 캐시 초기화 용이\n",
    "\n",
    "2. **프로덕션 환경**: SQLite Cache 또는 Redis Cache 사용\n",
    "   - 영구 저장 필요\n",
    "   - 여러 프로세스 간 캐시 공유\n",
    "\n",
    "3. **캐시 무효화 전략**\n",
    "   - 시간 기반: 일정 시간 후 캐시 만료\n",
    "   - 이벤트 기반: 데이터 변경 시 캐시 삭제\n",
    "   - 수동: 필요 시 캐시 파일 삭제\n",
    "\n",
    "4. **주의사항**\n",
    "   - 민감한 정보는 캐시하지 않기\n",
    "   - 캐시 크기 모니터링\n",
    "   - 정기적인 캐시 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7xhxrglmp9d",
   "metadata": {},
   "source": [
    "### 실전 예제: 대화형 챗봇에서 캐시 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bvyq6mfzhr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실전 예제: FAQ 챗봇 with 캐싱\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# SQLite 캐시 설정 (영구 저장)\n",
    "set_llm_cache(SQLiteCache(database_path=\"faq_cache.db\"))\n",
    "\n",
    "# FAQ 템플릿\n",
    "faq_template = ChatPromptTemplate.from_template(\n",
    "    \"당신은 친절한 고객 지원 챗봇입니다. 다음 질문에 간결하고 정확하게 답변해주세요: {question}\"\n",
    ")\n",
    "\n",
    "# 자주 묻는 질문들\n",
    "faqs = [\n",
    "    \"환불 정책이 어떻게 되나요?\",\n",
    "    \"배송 기간은 얼마나 걸리나요?\",\n",
    "    \"회원가입 혜택은 무엇인가요?\",\n",
    "    \"환불 정책이 어떻게 되나요?\",  # 중복 질문\n",
    "    \"배송 기간은 얼마나 걸리나요?\"   # 중복 질문\n",
    "]\n",
    "\n",
    "print(\"FAQ 챗봇 시뮬레이션 (캐싱 활용)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_time = 0\n",
    "cached_count = 0\n",
    "\n",
    "for i, question in enumerate(faqs, 1):\n",
    "    print(f\"\\n질문 {i}: {question}\")\n",
    "    \n",
    "    # 프롬프트 생성\n",
    "    prompt = faq_template.format_messages(question=question)\n",
    "    \n",
    "    # 응답 시간 측정\n",
    "    start_time = time.time()\n",
    "    response = llm.invoke(prompt)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    total_time += elapsed_time\n",
    "    \n",
    "    # 캐시 상태 표시\n",
    "    if elapsed_time < 0.1:\n",
    "        print(\"✅ 캐시된 응답 사용\")\n",
    "        cached_count += 1\n",
    "    else:\n",
    "        print(\"🔄 새로운 응답 생성\")\n",
    "    \n",
    "    print(f\"응답 시간: {elapsed_time:.3f}초\")\n",
    "    print(f\"답변: {response.content[:100]}...\")\n",
    "\n",
    "# 통계\n",
    "print(f\"\\n\\n📊 캐싱 통계:\")\n",
    "print(f\"- 총 질문 수: {len(faqs)}\")\n",
    "print(f\"- 캐시 히트: {cached_count}회\")\n",
    "print(f\"- 캐시 히트율: {cached_count/len(faqs)*100:.0f}%\")\n",
    "print(f\"- 총 응답 시간: {total_time:.2f}초\")\n",
    "print(f\"- 평균 응답 시간: {total_time/len(faqs):.3f}초\")\n",
    "\n",
    "# SQLite 캐시 연결 정리\n",
    "print(f\"\\n🧹 캐시 연결 정리 중...\")\n",
    "from langchain.globals import get_llm_cache\n",
    "\n",
    "# 현재 캐시 인스턴스 가져오기\n",
    "current_cache = get_llm_cache()\n",
    "if current_cache and hasattr(current_cache, 'engine'):\n",
    "    current_cache.engine.dispose()\n",
    "    print(\"✅ SQLite 연결 정리 완료\")\n",
    "\n",
    "# 캐시 무효화\n",
    "set_llm_cache(None)\n",
    "print(\"✅ 캐시 무효화 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ncc9afs6zi",
   "metadata": {},
   "source": [
    "## 정리\n",
    "\n",
    "이 노트북에서는 LangChain의 캐싱 기능을 배웠습니다:\n",
    "\n",
    "1. **LangSmith 연결**: LLM 호출 추적 및 모니터링\n",
    "2. **InMemory Cache**: 빠르고 간단한 메모리 기반 캐싱\n",
    "3. **SQLite Cache**: 영구 저장이 가능한 데이터베이스 기반 캐싱\n",
    "\n",
    "캐싱을 통해:\n",
    "- API 호출 비용을 크게 절감\n",
    "- 응답 속도를 수십~수백 배 향상\n",
    "- 일관된 응답 보장\n",
    "\n",
    "프로젝트의 요구사항에 맞는 캐싱 전략을 선택하여 효율적인 LLM 애플리케이션을 구축하세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v3pdksifybc",
   "metadata": {},
   "source": [
    "### 캐시 파일 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m0bty05ak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 캐시 파일 정리 (선택사항)\n",
    "import os\n",
    "\n",
    "cache_files = [\"langchain_cache.db\", \"faq_cache.db\"]\n",
    "\n",
    "for cache_file in cache_files:\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"캐시 파일 발견: {cache_file} ({os.path.getsize(cache_file)/1024:.2f} KB)\")\n",
    "        # 파일을 삭제하려면 아래 줄의 주석을 해제하세요\n",
    "        safe_remove_file(cache_file)\n",
    "        print(f\"  -> 삭제됨\")\n",
    "    else:\n",
    "        print(f\"캐시 파일 없음: {cache_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
