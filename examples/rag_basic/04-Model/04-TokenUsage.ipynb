{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95c71f2",
   "metadata": {},
   "source": [
    "# LangChain 토큰 사용량 확인 가이드\n",
    "\n",
    "이 노트북에서는 LangChain과 Gemini 모델을 사용할 때 토큰 사용량을 확인하고 관리하는 방법을 배웁니다.\n",
    "\n",
    "## 목차\n",
    "1. 환경 설정 및 LangSmith 연결\n",
    "2. 기본 토큰 사용량 확인\n",
    "3. `get_num_tokens()` 메서드 사용법\n",
    "4. 콜백을 통한 토큰 추적\n",
    "5. LangSmith를 통한 토큰 모니터링\n",
    "6. 배치 처리 시 토큰 사용량\n",
    "7. 토큰 사용량 최적화 팁\n",
    "\n",
    "## 토큰이란?\n",
    "\n",
    "**토큰(Token)**은 AI 모델이 텍스트를 처리하는 기본 단위입니다:\n",
    "- **영어**: 보통 1개 단어 = 1~2개 토큰\n",
    "- **한국어**: 보통 1개 음절 = 1개 토큰\n",
    "- **특수문자와 공백**도 토큰으로 계산\n",
    "\n",
    "## 토큰 관리의 중요성\n",
    "\n",
    "1. **비용 최적화**: 대부분의 AI API는 토큰 수에 따라 요금 부과\n",
    "2. **성능 향상**: 토큰 수가 적을수록 응답 속도 향상\n",
    "3. **모델 제한**: 각 모델마다 최대 토큰 제한이 있음\n",
    "4. **리소스 관리**: 토큰 사용량을 모니터링하여 효율적인 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c3886a",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 LangSmith 연결\n",
    "\n",
    "먼저 필요한 패키지를 임포트하고 LangSmith를 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01131a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "import time\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 확인\n",
    "print(\"🔍 환경 변수 확인 중...\")\n",
    "\n",
    "# Google API 키 확인\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if google_api_key:\n",
    "    print(\"✅ Google API Key: 설정됨\")\n",
    "else:\n",
    "    print(\"⚠️  Google API Key가 설정되지 않았습니다.\")\n",
    "\n",
    "# OpenAI API 키 확인 (대안)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key:\n",
    "    print(\"✅ OpenAI API Key: 설정됨\")\n",
    "else:\n",
    "    print(\"⚠️  OpenAI API Key가 설정되지 않았습니다.\")\n",
    "\n",
    "if not google_api_key and not openai_api_key:\n",
    "    print(\"❌ 사용 가능한 API 키가 없습니다.\")\n",
    "    print(\"   .env 파일에 GOOGLE_API_KEY 또는 OPENAI_API_KEY를 설정하세요.\")\n",
    "    print(\"   시뮬레이션 모드로 진행됩니다.\")\n",
    "\n",
    "# LangSmith API 키 확인 및 설정\n",
    "langsmith_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "if langsmith_api_key:\n",
    "    print(\"✅ LangSmith API Key: 설정됨\")\n",
    "    # LangSmith 설정\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"CH04-Models\"  # 프로젝트 이름 설정\n",
    "    \n",
    "    print(f\"📊 LangSmith 프로젝트: {os.environ['LANGCHAIN_PROJECT']}\")\n",
    "    print(f\"🔄 LangSmith 추적 활성화: {os.environ['LANGCHAIN_TRACING_V2']}\")\n",
    "    print(\"🌐 LangSmith 대시보드: https://smith.langchain.com/\")\n",
    "else:\n",
    "    print(\"⚠️  LangSmith API Key가 설정되지 않았습니다.\")\n",
    "    print(\"   토큰 추적은 콜백을 통해서만 가능합니다.\")\n",
    "\n",
    "print(\"\\n✅ 환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c13b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 - 우선순위: OpenAI > Gemini > 시뮬레이션\n",
    "llm = None\n",
    "model_type = \"simulation\"\n",
    "\n",
    "# 1. OpenAI 모델 시도 (추천)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if openai_api_key:\n",
    "    try:\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        print(\"🤖 OpenAI GPT-3.5-turbo 모델 사용!\")\n",
    "        model_type = \"openai\"\n",
    "        \n",
    "        # 간단한 테스트\n",
    "        print(\"🧪 모델 연결 테스트...\")\n",
    "        test_response = llm.invoke(\"Hi\")\n",
    "        print(f\"✅ OpenAI 모델 테스트 성공!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  OpenAI 모델 초기화 실패: {e}\")\n",
    "        llm = None\n",
    "\n",
    "# 2. Gemini 모델 시도 (OpenAI가 실패한 경우)\n",
    "if llm is None:\n",
    "    google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if google_api_key:\n",
    "        try:\n",
    "            llm = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-1.5-flash\",\n",
    "                temperature=0.7,\n",
    "                max_output_tokens=200\n",
    "            )\n",
    "            print(\"🤖 Gemini 모델 사용!\")\n",
    "            model_type = \"gemini\"\n",
    "            \n",
    "            # 간단한 테스트 (할당량 초과 시 건너뛰기)\n",
    "            print(\"🧪 모델 연결 테스트...\")\n",
    "            test_response = llm.invoke(\"Hi\")\n",
    "            print(f\"✅ Gemini 모델 테스트 성공!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Gemini 모델 사용 불가: {str(e)[:100]}...\")\n",
    "            if \"quota\" in str(e).lower() or \"429\" in str(e):\n",
    "                print(\"   → API 할당량 초과로 인한 오류입니다.\")\n",
    "            llm = None\n",
    "\n",
    "# 3. 시뮬레이션 모드 (모든 API가 실패한 경우)\n",
    "if llm is None:\n",
    "    print(\"🔧 시뮬레이션 모드로 전환!\")\n",
    "    print(\"   → 실제 LLM 호출 없이 토큰 계산 및 데모를 진행합니다.\")\n",
    "    model_type = \"simulation\"\n",
    "    \n",
    "    # 시뮬레이션용 가짜 LLM 클래스\n",
    "    class SimulationLLM:\n",
    "        def __init__(self):\n",
    "            self.model = \"simulation-model\"\n",
    "            self.temperature = 0.7\n",
    "            \n",
    "        def get_num_tokens(self, text):\n",
    "            # 대략적인 토큰 계산 (영어: 4문자당 1토큰, 한국어: 1문자당 1토큰)\n",
    "            korean_chars = len([c for c in text if ord(c) > 127])\n",
    "            english_chars = len(text) - korean_chars\n",
    "            return korean_chars + (english_chars // 4)\n",
    "        \n",
    "        def invoke(self, messages):\n",
    "            # 시뮬레이션 응답\n",
    "            class SimResponse:\n",
    "                def __init__(self):\n",
    "                    self.content = \"시뮬레이션 모드 응답입니다. 실제 LLM은 호출되지 않았습니다.\"\n",
    "            return SimResponse()\n",
    "    \n",
    "    llm = SimulationLLM()\n",
    "\n",
    "# 모델 정보 출력\n",
    "print(f\"\\n📋 최종 모델 설정:\")\n",
    "print(f\"   🤖 모델: {llm.model if hasattr(llm, 'model') else 'Unknown'}\")\n",
    "print(f\"   🌡️  온도: {llm.temperature if hasattr(llm, 'temperature') else 'Unknown'}\")\n",
    "print(f\"   🔧 모드: {model_type}\")\n",
    "\n",
    "if model_type == \"simulation\":\n",
    "    print(f\"\\n💡 시뮬레이션 모드 안내:\")\n",
    "    print(f\"   • 토큰 계산 기능은 정상 작동합니다\")\n",
    "    print(f\"   • LLM 호출이 필요한 셀은 시뮬레이션 데이터를 사용합니다\")\n",
    "    print(f\"   • 실제 API 비용이 발생하지 않습니다\")\n",
    "\n",
    "print(f\"\\n✅ 모델 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8288507",
   "metadata": {},
   "source": [
    "## 2. 기본 토큰 사용량 확인\n",
    "\n",
    "LangChain에서 토큰 사용량을 확인하는 가장 기본적인 방법들을 알아봅시다.\n",
    "\n",
    "### 토큰 계산 방법\n",
    "1. **`get_num_tokens()`**: 텍스트의 토큰 수 미리 계산\n",
    "2. **응답 메타데이터**: 실제 API 호출 후 사용된 토큰 확인\n",
    "3. **콜백 핸들러**: 실시간 토큰 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1681afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 응답 메타데이터를 통한 토큰 사용량 확인\n",
    "############################################################################\n",
    "\n",
    "print(\"📊 응답 메타데이터를 통한 토큰 사용량 확인\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 다양한 길이의 질문으로 테스트\n",
    "test_questions = [\n",
    "    \"안녕하세요!\",\n",
    "    \"Python 프로그래밍의 장점 3가지를 알려주세요.\",\n",
    "    \"인공지능과 머신러닝의 차이점을 상세히 설명하고, 각각의 활용 분야와 미래 전망에 대해 설명해주세요.\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{i}. 질문: {question}\")\n",
    "    print(f\"   질문 길이: {len(question)} 문자\")\n",
    "    \n",
    "    # 메시지 생성\n",
    "    message = HumanMessage(content=question)\n",
    "    \n",
    "    # API 호출\n",
    "    response = llm.invoke([message])\n",
    "    \n",
    "    # 응답 정보\n",
    "    print(f\"   응답: {response.content[:50]}...\")\n",
    "    print(f\"   응답 길이: {len(response.content)} 문자\")\n",
    "    \n",
    "    # 메타데이터에서 토큰 정보 확인\n",
    "    if hasattr(response, 'response_metadata'):\n",
    "        metadata = response.response_metadata\n",
    "        print(f\"   📈 메타데이터: {metadata}\")\n",
    "        \n",
    "        # 토큰 사용량 정보 추출\n",
    "        if 'usage_metadata' in metadata:\n",
    "            usage = metadata['usage_metadata']\n",
    "            print(f\"   🎯 입력 토큰: {usage.get('prompt_tokens', 'N/A')}\")\n",
    "            print(f\"   🎯 출력 토큰: {usage.get('completion_tokens', 'N/A')}\")\n",
    "            print(f\"   🎯 총 토큰: {usage.get('total_tokens', 'N/A')}\")\n",
    "        else:\n",
    "            print(f\"   ⚠️  토큰 정보가 메타데이터에 없습니다.\")\n",
    "    else:\n",
    "        print(f\"   ⚠️  응답에 메타데이터가 없습니다.\")\n",
    "\n",
    "print(\"\\n✅ 메타데이터 토큰 확인 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec626e",
   "metadata": {},
   "source": [
    "## 3. `get_num_tokens()` 메서드 사용법\n",
    "\n",
    "`get_num_tokens()` 메서드를 사용하면 실제 API를 호출하기 전에 텍스트의 토큰 수를 미리 계산할 수 있습니다.\n",
    "\n",
    "### 주요 활용 사례\n",
    "- **비용 예측**: API 호출 전 비용 계산\n",
    "- **토큰 제한 확인**: 모델의 최대 토큰 제한 준수\n",
    "- **프롬프트 최적화**: 토큰 수를 고려한 프롬프트 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1edb2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# get_num_tokens() 메서드를 사용한 토큰 수 계산\n",
    "############################################################################\n",
    "\n",
    "print(\"🔢 get_num_tokens() 메서드를 사용한 토큰 계산\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 다양한 텍스트로 테스트\n",
    "test_texts = [\n",
    "    \"안녕하세요!\",\n",
    "    \"Hello, world!\",\n",
    "    \"Python은 배우기 쉽고 강력한 프로그래밍 언어입니다.\",\n",
    "    \"LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크입니다. 다양한 컴포넌트를 제공하여 복잡한 AI 워크플로우를 쉽게 구축할 수 있습니다.\",\n",
    "    \"\"\"\n",
    "    긴 텍스트 예제입니다. \n",
    "    여러 줄에 걸친 텍스트의 토큰 수를 계산해봅시다.\n",
    "    토큰 계산은 모델마다 다를 수 있으며,\n",
    "    한국어와 영어의 토큰 계산 방식도 다릅니다.\n",
    "    이런 차이점을 이해하는 것이 중요합니다.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\"📝 텍스트별 토큰 수 분석:\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    # 토큰 수 계산\n",
    "    try:\n",
    "        token_count = llm.get_num_tokens(text)\n",
    "        char_count = len(text)\n",
    "        \n",
    "        print(f\"\\n{i}. 텍스트: {text[:50]}{'...' if len(text) > 50 else ''}\")\n",
    "        print(f\"   📏 문자 수: {char_count}\")\n",
    "        print(f\"   🎯 토큰 수: {token_count}\")\n",
    "        print(f\"   📊 토큰/문자 비율: {token_count/char_count:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{i}. 텍스트: {text[:50]}{'...' if len(text) > 50 else ''}\")\n",
    "        print(f\"   ❌ 토큰 계산 실패: {e}\")\n",
    "\n",
    "# 메시지 객체의 토큰 수 계산\n",
    "print(f\"\\n🔍 메시지 객체의 토큰 수 계산:\")\n",
    "messages = [\n",
    "    SystemMessage(content=\"당신은 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    HumanMessage(content=\"Python 프로그래밍에 대해 간단히 설명해주세요.\")\n",
    "]\n",
    "\n",
    "try:\n",
    "    total_tokens = llm.get_num_tokens_from_messages(messages)\n",
    "    print(f\"   📨 전체 메시지 토큰 수: {total_tokens}\")\n",
    "    \n",
    "    for i, msg in enumerate(messages):\n",
    "        individual_tokens = llm.get_num_tokens(msg.content)\n",
    "        print(f\"   📩 메시지 {i+1} ({type(msg).__name__}): {individual_tokens} 토큰\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ❌ 메시지 토큰 계산 실패: {e}\")\n",
    "    # 개별 메시지로 계산 시도\n",
    "    total = 0\n",
    "    for i, msg in enumerate(messages):\n",
    "        try:\n",
    "            tokens = llm.get_num_tokens(msg.content)\n",
    "            total += tokens\n",
    "            print(f\"   📩 메시지 {i+1} ({type(msg).__name__}): {tokens} 토큰\")\n",
    "        except Exception as e2:\n",
    "            print(f\"   ❌ 메시지 {i+1} 계산 실패: {e2}\")\n",
    "    print(f\"   📨 개별 계산 총합: {total} 토큰\")\n",
    "\n",
    "print(\"\\n✅ get_num_tokens() 실습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779fe839",
   "metadata": {},
   "source": [
    "## 4. 콜백을 통한 토큰 추적\n",
    "\n",
    "콜백 핸들러를 사용하면 실시간으로 토큰 사용량을 추적하고 로깅할 수 있습니다.\n",
    "\n",
    "### 콜백의 장점\n",
    "- **실시간 모니터링**: API 호출 중 토큰 사용량 실시간 확인\n",
    "- **세부 추적**: 각 단계별 토큰 사용량 상세 분석\n",
    "- **커스텀 로깅**: 원하는 형태로 토큰 정보 기록\n",
    "- **비용 관리**: 실시간 비용 계산 및 알림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ee0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 토큰 추적을 위한 커스텀 콜백 핸들러 구현\n",
    "############################################################################\n",
    "\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from typing import Any, Dict, List\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import LLMResult\n",
    "\n",
    "class TokenUsageCallback(BaseCallbackHandler):\n",
    "    \"\"\"토큰 사용량을 추적하는 커스텀 콜백 핸들러\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_prompt_tokens = 0\n",
    "        self.total_completion_tokens = 0\n",
    "        self.call_count = 0\n",
    "        self.cost_per_1k_tokens = 0.001  # Gemini Flash 예상 비용 (USD)\n",
    "        self.calls_history = []\n",
    "    \n",
    "    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:\n",
    "        \"\"\"LLM 호출 시작 시 실행\"\"\"\n",
    "        self.call_count += 1\n",
    "        print(f\"\\n🚀 LLM 호출 #{self.call_count} 시작\")\n",
    "        print(f\"   📝 프롬프트 수: {len(prompts)}\")\n",
    "        \n",
    "        # 프롬프트의 예상 토큰 수 계산 (가능한 경우)\n",
    "        for i, prompt in enumerate(prompts):\n",
    "            print(f\"   📄 프롬프트 {i+1}: {prompt[:50]}...\")\n",
    "    \n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "        \"\"\"LLM 호출 완료 시 실행\"\"\"\n",
    "        print(f\"✅ LLM 호출 #{self.call_count} 완료\")\n",
    "        \n",
    "        # 토큰 사용량 정보 추출\n",
    "        if response.llm_output:\n",
    "            usage = response.llm_output.get('usage_metadata', {})\n",
    "            \n",
    "            prompt_tokens = usage.get('prompt_tokens', 0)\n",
    "            completion_tokens = usage.get('completion_tokens', 0)\n",
    "            total_tokens_call = usage.get('total_tokens', 0)\n",
    "            \n",
    "            # 누적 통계 업데이트\n",
    "            self.total_prompt_tokens += prompt_tokens\n",
    "            self.total_completion_tokens += completion_tokens\n",
    "            self.total_tokens += total_tokens_call\n",
    "            \n",
    "            # 이번 호출 정보 저장\n",
    "            call_info = {\n",
    "                'call_number': self.call_count,\n",
    "                'prompt_tokens': prompt_tokens,\n",
    "                'completion_tokens': completion_tokens,\n",
    "                'total_tokens': total_tokens_call,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "            self.calls_history.append(call_info)\n",
    "            \n",
    "            # 상세 정보 출력\n",
    "            print(f\"   🎯 이번 호출 토큰:\")\n",
    "            print(f\"      입력: {prompt_tokens} 토큰\")\n",
    "            print(f\"      출력: {completion_tokens} 토큰\")\n",
    "            print(f\"      총합: {total_tokens_call} 토큰\")\n",
    "            \n",
    "            # 예상 비용 계산\n",
    "            estimated_cost = (total_tokens_call / 1000) * self.cost_per_1k_tokens\n",
    "            print(f\"   💰 예상 비용: ${estimated_cost:.6f}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"   ⚠️  토큰 사용량 정보를 찾을 수 없습니다.\")\n",
    "    \n",
    "    def on_llm_error(self, error: Exception, **kwargs) -> None:\n",
    "        \"\"\"LLM 호출 에러 시 실행\"\"\"\n",
    "        print(f\"❌ LLM 호출 #{self.call_count} 에러: {error}\")\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"토큰 사용량 요약 정보 반환\"\"\"\n",
    "        total_cost = (self.total_tokens / 1000) * self.cost_per_1k_tokens\n",
    "        \n",
    "        summary = {\n",
    "            'total_calls': self.call_count,\n",
    "            'total_tokens': self.total_tokens,\n",
    "            'total_prompt_tokens': self.total_prompt_tokens,\n",
    "            'total_completion_tokens': self.total_completion_tokens,\n",
    "            'estimated_total_cost': total_cost,\n",
    "            'average_tokens_per_call': self.total_tokens / max(self.call_count, 1),\n",
    "            'calls_history': self.calls_history\n",
    "        }\n",
    "        return summary\n",
    "    \n",
    "    def print_summary(self):\n",
    "        \"\"\"토큰 사용량 요약을 예쁘게 출력\"\"\"\n",
    "        summary = self.get_summary()\n",
    "        \n",
    "        print(f\"\\n📊 토큰 사용량 요약\")\n",
    "        print(f\"=\" * 40)\n",
    "        print(f\"🔢 총 호출 수: {summary['total_calls']}\")\n",
    "        print(f\"🎯 총 토큰 수: {summary['total_tokens']:,}\")\n",
    "        print(f\"   ├─ 입력 토큰: {summary['total_prompt_tokens']:,}\")\n",
    "        print(f\"   └─ 출력 토큰: {summary['total_completion_tokens']:,}\")\n",
    "        print(f\"📊 호출당 평균: {summary['average_tokens_per_call']:.1f} 토큰\")\n",
    "        print(f\"💰 예상 총 비용: ${summary['estimated_total_cost']:.6f}\")\n",
    "\n",
    "# 콜백 핸들러 인스턴스 생성\n",
    "token_callback = TokenUsageCallback()\n",
    "print(\"✅ 토큰 추적 콜백 핸들러 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 콜백 핸들러를 사용한 토큰 추적 테스트\n",
    "############################################################################\n",
    "\n",
    "print(\"🧪 콜백 핸들러를 사용한 토큰 추적 테스트\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 테스트 질문들\n",
    "test_questions = [\n",
    "    \"안녕하세요!\",\n",
    "    \"Python의 주요 특징 3가지를 알려주세요.\",\n",
    "    \"머신러닝과 딥러닝의 차이점을 설명하고, 각각의 대표적인 알고리즘을 예를 들어 설명해주세요.\"\n",
    "]\n",
    "\n",
    "# 각 질문에 대해 콜백과 함께 LLM 호출\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*20} 질문 {i} {'='*20}\")\n",
    "    print(f\"❓ 질문: {question}\")\n",
    "    \n",
    "    # 콜백을 포함하여 LLM 호출\n",
    "    response = llm.invoke(\n",
    "        [HumanMessage(content=question)],\n",
    "        config={\"callbacks\": [token_callback]}\n",
    "    )\n",
    "    \n",
    "    print(f\"💬 응답: {response.content}\")\n",
    "    print(f\"📏 응답 길이: {len(response.content)} 문자\")\n",
    "\n",
    "# 전체 토큰 사용량 요약 출력\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "token_callback.print_summary()\n",
    "\n",
    "# 세부 호출 이력 출력\n",
    "print(f\"\\n📋 세부 호출 이력:\")\n",
    "for call in token_callback.calls_history:\n",
    "    print(f\"   호출 #{call['call_number']}: \"\n",
    "          f\"입력 {call['prompt_tokens']} + 출력 {call['completion_tokens']} \"\n",
    "          f\"= 총 {call['total_tokens']} 토큰\")\n",
    "\n",
    "print(\"\\n✅ 콜백 기반 토큰 추적 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7961619",
   "metadata": {},
   "source": [
    "## 5. LangSmith를 통한 토큰 모니터링\n",
    "\n",
    "LangSmith는 LangChain 애플리케이션의 모니터링과 디버깅을 위한 플랫폼입니다. 토큰 사용량도 자동으로 추적됩니다.\n",
    "\n",
    "### LangSmith의 토큰 추적 기능\n",
    "- **자동 수집**: 모든 LLM 호출의 토큰 사용량 자동 기록\n",
    "- **시각화**: 대시보드를 통한 토큰 사용량 시각화\n",
    "- **비용 분석**: 프로젝트별, 시간별 비용 분석\n",
    "- **성능 모니터링**: 토큰 효율성 및 최적화 지점 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae35b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# LangSmith를 통한 토큰 추적 테스트\n",
    "############################################################################\n",
    "\n",
    "print(\"🌐 LangSmith를 통한 토큰 추적 테스트\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# LangSmith 추적 상태 확인\n",
    "langsmith_enabled = os.getenv(\"LANGCHAIN_TRACING_V2\") == \"true\"\n",
    "project_name = os.getenv(\"LANGCHAIN_PROJECT\", \"기본 프로젝트\")\n",
    "\n",
    "print(f\"📊 LangSmith 추적: {'✅ 활성화' if langsmith_enabled else '❌ 비활성화'}\")\n",
    "print(f\"📁 프로젝트명: {project_name}\")\n",
    "\n",
    "if langsmith_enabled:\n",
    "    print(f\"🌐 대시보드: https://smith.langchain.com/\")\n",
    "    print(f\"   → 프로젝트 '{project_name}'에서 실시간 토큰 사용량을 확인할 수 있습니다.\")\n",
    "    \n",
    "    # LangSmith 추적과 함께 체인 실행\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "    print(f\"\\n🔗 체인을 통한 LangSmith 추적 테스트\")\n",
    "    \n",
    "    # 간단한 체인 생성\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"다음 주제에 대해 간단히 설명해주세요: {topic}\"\n",
    "    )\n",
    "    parser = StrOutputParser()\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    # 여러 주제로 체인 실행\n",
    "    topics = [\"인공지능\", \"블록체인\", \"양자컴퓨팅\"]\n",
    "    \n",
    "    for topic in topics:\n",
    "        print(f\"\\n🎯 주제: {topic}\")\n",
    "        result = chain.invoke({\"topic\": topic})\n",
    "        print(f\"📝 응답: {result[:100]}...\")\n",
    "        print(f\"✅ LangSmith에 토큰 사용량이 기록되었습니다.\")\n",
    "    \n",
    "    print(f\"\\n💡 LangSmith 대시보드에서 다음 정보를 확인하세요:\")\n",
    "    print(f\"   • 각 호출의 토큰 사용량\")\n",
    "    print(f\"   • 입력/출력 토큰 분석\")\n",
    "    print(f\"   • 시간별 사용량 추이\")\n",
    "    print(f\"   • 비용 분석 및 예측\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n⚠️  LangSmith가 비활성화되어 있습니다.\")\n",
    "    print(f\"   환경 변수 LANGCHAIN_API_KEY를 설정하고 LANGCHAIN_TRACING_V2=true로 설정하세요.\")\n",
    "    \n",
    "    # LangSmith 없이도 기본 추적 시연\n",
    "    print(f\"\\n🔧 로컬 토큰 추적으로 대체 실행:\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"다음 주제에 대해 간단히 설명해주세요: {topic}\"\n",
    "    )\n",
    "    parser = StrOutputParser()\n",
    "    \n",
    "    # 새로운 콜백 인스턴스로 체인 테스트\n",
    "    local_callback = TokenUsageCallback()\n",
    "    \n",
    "    topics = [\"인공지능\", \"블록체인\"]\n",
    "    for topic in topics:\n",
    "        print(f\"\\n🎯 주제: {topic}\")\n",
    "        \n",
    "        # 각 단계별로 토큰 추적\n",
    "        formatted_prompt = prompt.format_messages(topic=topic)\n",
    "        response = llm.invoke(\n",
    "            formatted_prompt, \n",
    "            config={\"callbacks\": [local_callback]}\n",
    "        )\n",
    "        result = parser.invoke(response)\n",
    "        \n",
    "        print(f\"📝 응답: {result[:100]}...\")\n",
    "    \n",
    "    # 로컬 추적 결과 요약\n",
    "    local_callback.print_summary()\n",
    "\n",
    "print(f\"\\n✅ LangSmith 토큰 추적 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe46b0ae",
   "metadata": {},
   "source": [
    "## 6. 배치 처리 시 토큰 사용량\n",
    "\n",
    "여러 개의 요청을 배치로 처리할 때 토큰 사용량을 효율적으로 관리하는 방법을 알아봅시다.\n",
    "\n",
    "### 배치 처리의 장점\n",
    "- **비용 효율성**: 개별 호출보다 배치 처리가 일반적으로 더 효율적\n",
    "- **처리 속도**: 동시 처리로 전체 처리 시간 단축\n",
    "- **토큰 예측**: 전체 배치의 토큰 사용량 미리 계산 가능\n",
    "- **에러 처리**: 배치 단위로 에러 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4368589",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 배치 처리 시 토큰 사용량 관리\n",
    "############################################################################\n",
    "\n",
    "print(\"📦 배치 처리 시 토큰 사용량 관리\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 배치 처리용 질문 목록\n",
    "batch_questions = [\n",
    "    \"Python이란 무엇인가요?\",\n",
    "    \"머신러닝의 기본 개념을 설명해주세요.\",\n",
    "    \"딥러닝과 신경망의 관계는?\",\n",
    "    \"자연어 처리의 주요 기술들은?\",\n",
    "    \"LangChain의 핵심 기능은?\",\n",
    "    \"AI 윤리의 중요성은?\",\n",
    "    \"클라우드 컴퓨팅의 장점은?\",\n",
    "    \"데이터 과학자의 역할은?\"\n",
    "]\n",
    "\n",
    "print(f\"📋 배치 크기: {len(batch_questions)}개 질문\")\n",
    "\n",
    "# 1. 사전 토큰 계산\n",
    "print(f\"\\n1️⃣ 사전 토큰 계산\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "total_estimated_tokens = 0\n",
    "question_tokens = []\n",
    "\n",
    "for i, question in enumerate(batch_questions, 1):\n",
    "    try:\n",
    "        tokens = llm.get_num_tokens(question)\n",
    "        question_tokens.append(tokens)\n",
    "        total_estimated_tokens += tokens\n",
    "        print(f\"   질문 {i}: {tokens} 토큰 - {question}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   질문 {i}: 토큰 계산 실패 - {question}\")\n",
    "        question_tokens.append(0)\n",
    "\n",
    "print(f\"\\n📊 사전 계산 결과:\")\n",
    "print(f\"   총 입력 토큰 (예상): {total_estimated_tokens}\")\n",
    "print(f\"   평균 질문 길이: {total_estimated_tokens/len(batch_questions):.1f} 토큰\")\n",
    "\n",
    "# 출력 토큰 예상 (평균적으로 입력의 2-3배 가정)\n",
    "estimated_output_tokens = total_estimated_tokens * 2.5\n",
    "estimated_total = total_estimated_tokens + estimated_output_tokens\n",
    "estimated_cost = (estimated_total / 1000) * 0.001\n",
    "\n",
    "print(f\"   예상 출력 토큰: {estimated_output_tokens:.0f}\")\n",
    "print(f\"   예상 총 토큰: {estimated_total:.0f}\")\n",
    "print(f\"   예상 비용: ${estimated_cost:.6f}\")\n",
    "\n",
    "# 2. 배치 실행 (콜백과 함께)\n",
    "print(f\"\\n2️⃣ 배치 실행 (토큰 추적)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "batch_callback = TokenUsageCallback()\n",
    "batch_responses = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i, question in enumerate(batch_questions, 1):\n",
    "    print(f\"\\n⏳ 처리 중: {i}/{len(batch_questions)} - {question[:30]}...\")\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(\n",
    "            [HumanMessage(content=question)],\n",
    "            config={\"callbacks\": [batch_callback]}\n",
    "        )\n",
    "        batch_responses.append({\n",
    "            'question': question,\n",
    "            'response': response.content,\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 에러: {e}\")\n",
    "        batch_responses.append({\n",
    "            'question': question,\n",
    "            'response': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "\n",
    "# 3. 배치 처리 결과 분석\n",
    "print(f\"\\n3️⃣ 배치 처리 결과 분석\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "successful_responses = [r for r in batch_responses if r['success']]\n",
    "failed_responses = [r for r in batch_responses if not r['success']]\n",
    "\n",
    "print(f\"✅ 성공: {len(successful_responses)}개\")\n",
    "print(f\"❌ 실패: {len(failed_responses)}개\")\n",
    "print(f\"⏱️  총 처리 시간: {processing_time:.2f}초\")\n",
    "print(f\"📊 평균 처리 시간: {processing_time/len(batch_questions):.2f}초/질문\")\n",
    "\n",
    "# 토큰 사용량 요약\n",
    "batch_callback.print_summary()\n",
    "\n",
    "# 실제 vs 예상 비교\n",
    "actual_total = batch_callback.total_tokens\n",
    "prediction_accuracy = (1 - abs(estimated_total - actual_total) / actual_total) * 100\n",
    "\n",
    "print(f\"\\n📈 예상 vs 실제 비교:\")\n",
    "print(f\"   예상 총 토큰: {estimated_total:.0f}\")\n",
    "print(f\"   실제 총 토큰: {actual_total}\")\n",
    "print(f\"   예측 정확도: {prediction_accuracy:.1f}%\")\n",
    "\n",
    "# 4. 응답 샘플 출력\n",
    "print(f\"\\n4️⃣ 응답 샘플 (처음 3개)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, response in enumerate(successful_responses[:3], 1):\n",
    "    print(f\"\\n질문 {i}: {response['question']}\")\n",
    "    print(f\"응답: {response['response'][:100]}...\")\n",
    "\n",
    "print(f\"\\n✅ 배치 처리 토큰 관리 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167904fc",
   "metadata": {},
   "source": [
    "## 7. 토큰 사용량 최적화 팁\n",
    "\n",
    "토큰 사용량을 최적화하여 비용을 절약하고 성능을 향상시키는 실용적인 방법들을 알아봅시다.\n",
    "\n",
    "### 최적화 전략\n",
    "1. **프롬프트 최적화**: 불필요한 단어 제거, 명확한 지시\n",
    "2. **응답 길이 제한**: `max_output_tokens` 설정으로 출력 제한\n",
    "3. **시스템 메시지 활용**: 반복적인 컨텍스트를 시스템 메시지로 분리\n",
    "4. **캐싱 활용**: 동일한 요청의 재사용\n",
    "5. **배치 처리**: 여러 요청을 효율적으로 묶어서 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49758071",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 토큰 사용량 최적화 실습\n",
    "############################################################################\n",
    "\n",
    "print(\"⚡ 토큰 사용량 최적화 실습\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. 프롬프트 최적화 비교\n",
    "print(\"1️⃣ 프롬프트 최적화 비교\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 비효율적인 프롬프트 vs 최적화된 프롬프트\n",
    "inefficient_prompt = \"\"\"\n",
    "안녕하세요! 저는 현재 Python 프로그래밍 언어에 대해서 배우고 있는 학생입니다. \n",
    "Python이라는 프로그래밍 언어가 다른 프로그래밍 언어들과 비교했을 때 어떤 장점들이 있는지, \n",
    "그리고 어떤 분야에서 주로 사용되고 있는지에 대해서 자세하고 친절하게 설명해주시면 감사하겠습니다. \n",
    "가능하면 예시도 함께 들어주세요.\n",
    "\"\"\"\n",
    "\n",
    "efficient_prompt = \"Python의 주요 장점 3가지와 활용 분야를 간단히 설명해주세요.\"\n",
    "\n",
    "# 토큰 수 비교\n",
    "inefficient_tokens = llm.get_num_tokens(inefficient_prompt.strip())\n",
    "efficient_tokens = llm.get_num_tokens(efficient_prompt)\n",
    "\n",
    "print(f\"❌ 비효율적 프롬프트:\")\n",
    "print(f\"   내용: {inefficient_prompt.strip()[:50]}...\")\n",
    "print(f\"   토큰 수: {inefficient_tokens}\")\n",
    "\n",
    "print(f\"\\n✅ 최적화된 프롬프트:\")\n",
    "print(f\"   내용: {efficient_prompt}\")\n",
    "print(f\"   토큰 수: {efficient_tokens}\")\n",
    "\n",
    "print(f\"\\n📊 최적화 결과:\")\n",
    "print(f\"   토큰 절약: {inefficient_tokens - efficient_tokens} 토큰\")\n",
    "print(f\"   절약률: {((inefficient_tokens - efficient_tokens) / inefficient_tokens * 100):.1f}%\")\n",
    "\n",
    "# 2. 응답 길이 제한 비교 (시뮬레이션)\n",
    "print(f\"\\n2️⃣ 응답 길이 제한 비교 (시뮬레이션)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "question = \"인공지능의 미래에 대해 설명해주세요.\"\n",
    "\n",
    "# 제한 없는 모델 설정\n",
    "unlimited_llm_config = {\n",
    "    \"model\": \"gemini-1.5-flash\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_output_tokens\": None  # 제한 없음\n",
    "}\n",
    "\n",
    "# 제한 있는 모델 설정\n",
    "limited_llm_config = {\n",
    "    \"model\": \"gemini-1.5-flash\", \n",
    "    \"temperature\": 0.7,\n",
    "    \"max_output_tokens\": 100  # 출력 제한\n",
    "}\n",
    "\n",
    "print(f\"질문: {question}\")\n",
    "print(f\"입력 토큰: {llm.get_num_tokens(question)}\")\n",
    "\n",
    "# API 호출 대신 시뮬레이션으로 대체\n",
    "print(f\"\\n🔓 제한 없는 응답 (시뮬레이션):\")\n",
    "print(f\"설정: {unlimited_llm_config}\")\n",
    "estimated_unlimited_output = 150  # 예상 출력 토큰\n",
    "unlimited_total_estimated = llm.get_num_tokens(question) + estimated_unlimited_output\n",
    "print(f\"예상 출력 토큰: {estimated_unlimited_output}\")\n",
    "print(f\"예상 총 토큰: {unlimited_total_estimated}\")\n",
    "\n",
    "print(f\"\\n🔒 길이 제한 응답 (시뮬레이션):\")\n",
    "print(f\"설정: {limited_llm_config}\")\n",
    "estimated_limited_output = 100  # 제한된 출력 토큰\n",
    "limited_total_estimated = llm.get_num_tokens(question) + estimated_limited_output\n",
    "print(f\"예상 출력 토큰: {estimated_limited_output}\")\n",
    "print(f\"예상 총 토큰: {limited_total_estimated}\")\n",
    "\n",
    "# 결과 비교\n",
    "print(f\"\\n📊 응답 길이 제한 효과 (시뮬레이션):\")\n",
    "print(f\"   제한 없음: {unlimited_total_estimated} 토큰\")\n",
    "print(f\"   제한 있음: {limited_total_estimated} 토큰\")\n",
    "print(f\"   절약: {unlimited_total_estimated - limited_total_estimated} 토큰\")\n",
    "\n",
    "if unlimited_total_estimated > 0:\n",
    "    savings_percent = ((unlimited_total_estimated - limited_total_estimated) / unlimited_total_estimated) * 100\n",
    "    print(f\"   절약률: {savings_percent:.1f}%\")\n",
    "\n",
    "print(f\"\\n💡 실제 환경에서는 max_output_tokens 설정으로 출력 토큰을 제한할 수 있습니다.\")\n",
    "\n",
    "# 3. 시스템 메시지 활용\n",
    "print(f\"\\n3️⃣ 시스템 메시지 활용\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 반복적인 컨텍스트가 포함된 질문들\n",
    "questions_with_context = [\n",
    "    \"당신은 Python 전문가입니다. Python의 리스트 comprehension에 대해 설명해주세요.\",\n",
    "    \"당신은 Python 전문가입니다. Python의 데코레이터에 대해 설명해주세요.\",\n",
    "    \"당신은 Python 전문가입니다. Python의 제너레이터에 대해 설명해주세요.\"\n",
    "]\n",
    "\n",
    "# 시스템 메시지 + 간단한 질문들\n",
    "system_message = SystemMessage(content=\"당신은 Python 전문가입니다.\")\n",
    "optimized_questions = [\n",
    "    \"리스트 comprehension에 대해 설명해주세요.\",\n",
    "    \"데코레이터에 대해 설명해주세요.\", \n",
    "    \"제너레이터에 대해 설명해주세요.\"\n",
    "]\n",
    "\n",
    "# 토큰 수 계산\n",
    "context_method_tokens = sum(llm.get_num_tokens(q) for q in questions_with_context)\n",
    "system_method_tokens = llm.get_num_tokens(system_message.content) + sum(llm.get_num_tokens(q) for q in optimized_questions)\n",
    "\n",
    "print(f\"❌ 반복 컨텍스트 방식:\")\n",
    "print(f\"   총 입력 토큰: {context_method_tokens}\")\n",
    "\n",
    "print(f\"\\n✅ 시스템 메시지 방식:\")\n",
    "print(f\"   시스템 메시지: {llm.get_num_tokens(system_message.content)} 토큰\")\n",
    "print(f\"   질문들: {sum(llm.get_num_tokens(q) for q in optimized_questions)} 토큰\")\n",
    "print(f\"   총 입력 토큰: {system_method_tokens}\")\n",
    "\n",
    "print(f\"\\n📊 시스템 메시지 최적화 결과:\")\n",
    "print(f\"   토큰 절약: {context_method_tokens - system_method_tokens} 토큰\")\n",
    "print(f\"   절약률: {((context_method_tokens - system_method_tokens) / context_method_tokens * 100):.1f}%\")\n",
    "\n",
    "print(f\"\\n✅ 토큰 최적화 실습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e09cede",
   "metadata": {},
   "source": [
    "## 정리 및 모범 사례\n",
    "\n",
    "이 노트북에서 배운 토큰 사용량 확인 및 관리 방법들을 정리해봅시다.\n",
    "\n",
    "### 🎯 주요 학습 내용\n",
    "\n",
    "1. **응답 메타데이터**: `response.response_metadata`에서 토큰 정보 확인\n",
    "2. **`get_num_tokens()`**: 사전 토큰 계산으로 비용 예측\n",
    "3. **콜백 핸들러**: 실시간 토큰 추적 및 상세 분석\n",
    "4. **LangSmith**: 자동 토큰 모니터링 및 시각화\n",
    "5. **배치 처리**: 대량 요청의 효율적인 토큰 관리\n",
    "6. **최적화 기법**: 프롬프트, 응답 길이, 시스템 메시지 최적화\n",
    "\n",
    "### 📋 토큰 관리 체크리스트\n",
    "\n",
    "| 단계 | 확인 사항 | 도구/방법 |\n",
    "|------|-----------|-----------|\n",
    "| **사전 계획** | 예상 토큰 수 계산 | `get_num_tokens()` |\n",
    "| **실행 중** | 실시간 토큰 추적 | 콜백 핸들러 |\n",
    "| **모니터링** | 장기적 사용량 분석 | LangSmith |\n",
    "| **최적화** | 토큰 효율성 개선 | 프롬프트 최적화 |\n",
    "\n",
    "### ⚠️ 주의사항\n",
    "\n",
    "1. **정확성**: 토큰 계산은 모델마다 다를 수 있음\n",
    "2. **비용 예측**: 실제 비용은 API 제공자의 정책에 따라 변동\n",
    "3. **성능 영향**: 과도한 토큰 추적은 성능에 영향을 줄 수 있음\n",
    "4. **메타데이터 의존성**: 모든 모델이 동일한 메타데이터를 제공하지 않음\n",
    "\n",
    "### 🚀 실전 활용 팁\n",
    "\n",
    "1. **개발 단계**: 콜백을 활용한 상세 토큰 분석\n",
    "2. **테스트 단계**: 배치 처리로 토큰 사용량 검증\n",
    "3. **프로덕션**: LangSmith로 지속적인 모니터링\n",
    "4. **최적화**: 정기적인 프롬프트 및 설정 최적화\n",
    "\n",
    "### 💡 비용 절약 요령\n",
    "\n",
    "- **짧고 명확한 프롬프트** 사용\n",
    "- **응답 길이 제한** 설정 (`max_output_tokens`)\n",
    "- **시스템 메시지** 활용으로 반복 컨텍스트 제거\n",
    "- **캐싱** 및 **배치 처리** 적극 활용\n",
    "- **정기적인 토큰 사용량 분석** 및 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c00f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# 종합 예제: 토큰 사용량 모니터링 시스템\n",
    "############################################################################\n",
    "\n",
    "print(\"🎯 종합 예제: 토큰 사용량 모니터링 시스템\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "class TokenMonitor:\n",
    "    \"\"\"토큰 사용량을 종합적으로 모니터링하는 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, llm, cost_per_1k_tokens=0.001):\n",
    "        self.llm = llm\n",
    "        self.cost_per_1k_tokens = cost_per_1k_tokens\n",
    "        self.callback = TokenUsageCallback()\n",
    "        self.sessions = []\n",
    "    \n",
    "    def estimate_tokens(self, text):\n",
    "        \"\"\"텍스트의 토큰 수 추정\"\"\"\n",
    "        try:\n",
    "            return self.llm.get_num_tokens(text)\n",
    "        except:\n",
    "            return len(text) // 4  # 대략적인 추정\n",
    "    \n",
    "    def process_with_monitoring(self, messages, session_name=\"기본 세션\"):\n",
    "        \"\"\"토큰 모니터링과 함께 메시지 처리\"\"\"\n",
    "        print(f\"\\n🔄 세션 시작: {session_name}\")\n",
    "        \n",
    "        # 사전 토큰 추정\n",
    "        if isinstance(messages, str):\n",
    "            messages = [HumanMessage(content=messages)]\n",
    "        elif isinstance(messages, list) and isinstance(messages[0], str):\n",
    "            messages = [HumanMessage(content=msg) for msg in messages]\n",
    "        \n",
    "        estimated_input = sum(self.estimate_tokens(msg.content) for msg in messages)\n",
    "        print(f\"   📊 예상 입력 토큰: {estimated_input}\")\n",
    "        \n",
    "        # 실제 처리\n",
    "        session_callback = TokenUsageCallback()\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke(\n",
    "                messages, \n",
    "                config={\"callbacks\": [session_callback]}\n",
    "            )\n",
    "            \n",
    "            # 세션 정보 저장\n",
    "            session_info = {\n",
    "                'name': session_name,\n",
    "                'estimated_input': estimated_input,\n",
    "                'actual_tokens': session_callback.total_tokens,\n",
    "                'response': response.content,\n",
    "                'success': True\n",
    "            }\n",
    "            self.sessions.append(session_info)\n",
    "            \n",
    "            print(f\"   ✅ 처리 완료\")\n",
    "            print(f\"   📈 실제 사용 토큰: {session_callback.total_tokens}\")\n",
    "            print(f\"   💰 세션 비용: ${(session_callback.total_tokens/1000)*self.cost_per_1k_tokens:.6f}\")\n",
    "            \n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            session_info = {\n",
    "                'name': session_name,\n",
    "                'estimated_input': estimated_input, \n",
    "                'actual_tokens': 0,\n",
    "                'response': None,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            }\n",
    "            self.sessions.append(session_info)\n",
    "            print(f\"   ❌ 처리 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_summary_report(self):\n",
    "        \"\"\"종합 리포트 생성\"\"\"\n",
    "        if not self.sessions:\n",
    "            return \"아직 처리된 세션이 없습니다.\"\n",
    "        \n",
    "        total_sessions = len(self.sessions)\n",
    "        successful_sessions = [s for s in self.sessions if s['success']]\n",
    "        failed_sessions = [s for s in self.sessions if not s['success']]\n",
    "        \n",
    "        total_tokens = sum(s['actual_tokens'] for s in successful_sessions)\n",
    "        total_cost = (total_tokens / 1000) * self.cost_per_1k_tokens\n",
    "        \n",
    "        accuracy_data = [(s['estimated_input'], s['actual_tokens']) for s in successful_sessions if s['actual_tokens'] > 0]\n",
    "        avg_accuracy = 0\n",
    "        if accuracy_data:\n",
    "            accuracies = [1 - abs(est - act) / act for est, act in accuracy_data if act > 0]\n",
    "            avg_accuracy = sum(accuracies) / len(accuracies) * 100\n",
    "        \n",
    "        report = f\"\"\"\n",
    "📊 토큰 사용량 종합 리포트\n",
    "{'='*40}\n",
    "🔢 총 세션 수: {total_sessions}개\n",
    "   ├─ 성공: {len(successful_sessions)}개\n",
    "   └─ 실패: {len(failed_sessions)}개\n",
    "\n",
    "🎯 토큰 사용량:\n",
    "   ├─ 총 토큰: {total_tokens:,}개\n",
    "   ├─ 평균/세션: {total_tokens/max(len(successful_sessions), 1):.1f}개\n",
    "   └─ 예측 정확도: {avg_accuracy:.1f}%\n",
    "\n",
    "💰 비용 정보:\n",
    "   ├─ 총 비용: ${total_cost:.6f}\n",
    "   └─ 평균/세션: ${total_cost/max(len(successful_sessions), 1):.6f}\n",
    "\n",
    "📋 세션별 상세:\"\"\"\n",
    "        \n",
    "        for i, session in enumerate(self.sessions[-5:], 1):  # 최근 5개만\n",
    "            status = \"✅\" if session['success'] else \"❌\"\n",
    "            tokens = session['actual_tokens'] if session['success'] else 0\n",
    "            report += f\"\\n   {status} {session['name']}: {tokens} 토큰\"\n",
    "        \n",
    "        if len(self.sessions) > 5:\n",
    "            report += f\"\\n   ... (총 {len(self.sessions)}개 세션)\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# 토큰 모니터 인스턴스 생성\n",
    "monitor = TokenMonitor(llm)\n",
    "\n",
    "# 다양한 세션으로 테스트\n",
    "test_sessions = [\n",
    "    (\"간단한 질문\", \"안녕하세요!\"),\n",
    "    (\"중간 길이 질문\", \"Python 프로그래밍의 장점을 3가지 알려주세요.\"),\n",
    "    (\"복잡한 질문\", \"머신러닝과 딥러닝의 차이점을 상세히 설명하고, 각각의 활용 분야와 미래 전망에 대해 논의해주세요.\")\n",
    "]\n",
    "\n",
    "print(\"🧪 다양한 세션으로 토큰 모니터링 테스트\")\n",
    "\n",
    "for session_name, question in test_sessions:\n",
    "    response = monitor.process_with_monitoring(question, session_name)\n",
    "    if response:\n",
    "        print(f\"   📝 응답: {response[:50]}...\")\n",
    "\n",
    "# 종합 리포트 출력\n",
    "print(monitor.get_summary_report())\n",
    "\n",
    "print(f\"\\n🎉 토큰 사용량 확인 가이드 완료!\")\n",
    "print(f\"💡 이제 여러분은 LangChain에서 토큰을 효율적으로 관리할 수 있습니다!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
